{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "Predicted label: cough with a confidence of 100.0 %\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "import librosa\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "\n",
    "def audio_recorder():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        frame =[]\n",
    "        second = 0\n",
    "        progress = 0\n",
    "        while True:\n",
    "            progress+=1\n",
    "            data = numpy.fromstring(stream.read(CHUNK),dtype=numpy.int16)\n",
    "            frame.append(data)\n",
    "            second = progress*CHUNK/RATE\n",
    "            # print(second)\n",
    "            if second >= 1:\n",
    "                break\n",
    "        audio_data = numpy.concatenate(frame).astype(numpy.float32)\n",
    "        onset_env = librosa.onset.onset_strength(y=audio_data, sr=RATE) \n",
    "        peaks = librosa.util.peak_pick(onset_env, pre_max=1, post_max=1, pre_avg=1, post_avg=1, delta=2, wait=5)\n",
    "        if len(peaks)>0:\n",
    "            getspectrogram(audio_data)\n",
    "            reconizer()\n",
    "            \n",
    "            \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "def getspectrogram(audio_data):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    D = numpy.abs(librosa.stft(audio_data))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(D, ref=numpy.max))\n",
    "    plt.style.use('dark_background')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"temp/\",'{}.png'.format('temp')) ,bbox_inches='tight',pad_inches=0)\n",
    "    # plt.show()\n",
    "    # print('saved image')\n",
    "\n",
    "def reconizer():\n",
    "    img = Image.open('temp/temp.png')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = numpy.array(img)\n",
    "    if img_array.shape[-1] == 4:\n",
    "        img_array = img_array[..., :3]\n",
    "    img_array = numpy.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    model = tf.keras.models.load_model('converted_keras/keras_model.h5')\n",
    "    prediction = model.predict(img_array)\n",
    "    labels = ['non-cough', 'cough']\n",
    "    predicted_label = labels[numpy.argmax(prediction)]\n",
    "    print('Predicted label:', predicted_label, 'with a confidence of', prediction[0][numpy.argmax(prediction)]*100, '%')\n",
    "    \n",
    "audio_recorder()\n",
    "# reconizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiopy1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
